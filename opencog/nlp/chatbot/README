
                       La Cogita Chatbot
                       -----------------
                Linas Vepstas <linasvepstas@gmail.com>
                          April 2009

A quick-n-dirty hookup of the OpenCog NLP pipeline to an IRC chatbot.

At this time, the bot is a demo of the OpenCog natural-language 
processing (NLP) pipeline; it is NOT -- repeat NOT -- a demo of
OpenCog reasoning, deduction, or anything like that.  The chatbot 
is as dumb as a rock, as thick as a brick; it possesses no intelligence
whatsoever.

It can, however, answer simple English-language questions. It does so
by comparing the syntactical structure of the question to previously
entered sentences.  Thus, for example, if the chatbot is told that 
"John threw a rock", and then asked "Who threw a rock?", direct 
comparison allows it to equate "Who" -> "John".  The comparisons are
done on the syntactic structure (dependency parse) of the sentence:
that is, the parsed form of the sentences and questions are compared.
This allows for some sophistication: the system can correctly answer
"What did John throw?" for the above input, because dependency parsing
will correctly identify "throw" as the head verb of the sentence.

Since OpenCog can save its contents to a database, it can "remember" 
a large number of assertions that have been previously entered, and 
answer questions about those.  Currently, a pre-parsed copy of the 
MIT ConceptNet can be loaded into OpenCog.

Please note: this is meant to be a DEMO of the NLP pipeline, and litle
more. It is up to you to do something with it!  Also: it is subject to 
change at any time, as I am likely to twiddle, tweak and change it about.
(Adding reasoning is a difficult but important priority).

Configuring: 
-----------
There is an assortment of hard-coded configuration stuff in the source
code.  See go-irc.c for setable values for the name of the chatbot, the
irc channel and irc network to join, and the bot ID strings, etc.

By default, it connects to the #opencog channel on freenode.net.

The bot tries to connect to an opencog server at port 17004. This port 
number is hard-coded in whirr-sockets.cc.

Running:
--------
After modifying the hard-coded config as desired, start the bot by 
saying "opencog/nlp/chatbot/cogita". It should then appear on the IRC
channel. You can then talk to it by addressing it by name, i.e. 
prefacing comments with cog:, cogita: or cogita-bot:

To have it do something, you must have an opencog server running on
port 17004, and have the opencog server appropriately loaded up with
assorted databses, code, etc.

You also have to have the latest version of RelEx installed, and then
run ./opencog-server.sh from the main RelEx directory. This will create
a parse server on port 4444: it will read plain-text input, and generate
parsed text in opencog format.  The chatbot needs this server to process
text.

This is most easily done by starting the cogserver using the 
lib/opencog-chatbot.conf configuration file, which sets the correct port,
silences the opencog prompt, and loads the needed scheme files.

In addition, triples-processing, described in step 4 below, requires
that the shell scripts opencog/nlp/triples/load-chatbot.sh and 
opencog/nlp/seme/load-chatbot.sh be run.

To enable the common-sense database (described in step 5), you must
first create and populate the database. This can be done from scratch,
or by using a database dump, obtained from 

       http://gnucash.org/linas/nlp/data/conceptnet/

The database should be created and populated, as described in 
opencog/nlp/triples/README.  Then, after starting opencog, but *before*
running load-chatbot.sh, telnet to the cogserver, and open the database:

     $ telnet localhost 17004
     cog-server> sql-open <dbname> <userid> <passwd>

For example:

     cog-server> sql-open triples linas asdf

Then do the two load-chatbot.sh files. The system is now ready to do 
question-answering.


Architecture:
-------------
The current architecture makes use of several servers interconnected
by TCP/IP sockets to perform NLP processing.  The infrastructure is
currently very minimalistic, and is just barely enough to get the job
done. All modifications require tampering the source code. The pipeline
is as follows:

1) IRC I/O, performed by cogita, which acts as a intermediary between
   IRC and OpenCog.  It listens for input on an IRC channel, and 
   forwards the resulting plain-text to opencog. This is done by
   issuing one simple scheme expression to opencog, via the opencog
   command-line interface/scheme shell on port 17004. The expression 
   is ''(say-id-english usernick text)'', where the ''usernick'' is 
   the user's IRC nick, and ''text'' is what the user entered.  The
   return value from this command is sent back to the IRC channel.
   Communications is stateless and blocking: cogita closes the socket
   to indicate end-of-messsage, and expects that the cog server will
   do the same. Only after the cog-server closes its socket does cogita
   reply on the IRC channel.

   IRC.cc,.h:  C++ class for generic IRC communications.
   go-irc.cc:  the main guts of the cogita server
   whirr-sockets.cc,.h: tcp socket to send data to opencog, get reply.  

   Note that if the cog-server is busy, then whirr can block for an
   indefinitely long time. The person who is chatting will start to 
   wonder about the lack of response. This should be fixed -- best
	fix is probably to multi-thread, while periodically telling the
	user that the cog server is thinking ...  XXX FIXME

2) Parsing of english text by RelEx. The very first thing that the 
   ''say-id-english'' routine does is to send the input text to RelEx
   for parsing.  This is done by sending the plain-text via a socket
   to a listening RelEx server; the server responds with the parsed
   text, in the form of a hypergraph of atoms expressed in scheme. 
   The hypergraph is then loaded into the opencog atomspace, and is
   ready for processing. 

   I/O to parser is stateless: RelEx will close the socket after it has
   completed its parse and returned its results. 

2a) Data flow.  Each newly parsed sentence is attached, via a ListLink, 
   to an AnchorNode "# New Parsed Sentence".  Later processing stages 
   use the same mechanism, of linking to AnchorNode's, to pass data to 
   each other.

3) Question-Answering. The bot can recognize some simple questions and
   answer them. This is doen by a very simple form of pattern-matching
   on RelEx output. Thus, for example, the dependency parse of "John
   threw the ball" results in "_subj(throw,John) _obj(throw,ball)".
   The question "Who threw a ball?" results in "_subj(throw,who) 
   _obj(throw,ball)". By taking "who" to mean "an unknown variable", 
   it is straight-forward to pattern-match the statement to the question,
   and determine that "who" corresponds to "John".

   The set-up for RelEx-based matching is done in nlp/question/RelexQuery.cc.
   The actual pattern-matching is done by generic hypergraph predicate
   maching code in query/PatternMatchEngine.cc.

4) Semantic triples. The scope of questions that can be answered can be
   slightly broadened by converting them into a normalized form, here
   refered to as a "semantic triple." An example would be the 
   prepositional phrase "color_of(sky,blue)", a form that is shared by
   both the statement and question "The color of the sky is blue" and
   "What is the color of the sky?" even though the RelEx dependency 
   parses of the statement and the question are quite different.
   
   Code to extract and create such triples is in the nlp/triples 
   directory. The pattern-matching for such triples is done by 
   nlp/question/TripleQuery.cc.  This code is triggered and run
   if the process in step-3 fails for find an answer (although
   triples are extracted for all new statements, in case they are
   needed for question-answering later.

5) Common sense database. The semantic-triple format allows a 
   repository of common-sense triples to be created, and questions 
   to be answered from such previously-read input. A dataset of
   common-sense assertions, written in English, is available from the
   MIT ConceptNet project. It contains sentences such as 
   "Baseball is a sport."  This dataset may be loaded into OpenCog by 
   following the instructions in nlp/triples/README.  Alternately, 
   SQL dumps, suitable for immediate use, can be downloaded from 

       http://gnucash.org/linas/nlp/data/conceptnet/

   If the database has been opened, then the same code as described in 
   the previous step, above, will look for answers to questions there.
   
6) Frames.  (Not hooked up) Additional context can be provided by 
   frame-net-like frames. There's code in RelEx for this, its not
   hooked up.
    
7) Reasoning (not implemented). In principle, reasoning could be done.
   Right now, there is no infrastructure for this, aside from the core
   reasoning engine, PLN itself.  All details for how to go about doing
   this are yet to be fleshed out.

8) NLgen (not yet hooked up). Natural language output.
   Code at https://launchpad.net/nlgen 
   Overview at http://www.opencog.org/wiki/SegSim



