
                          Semantic Triples
                          ----------------
                      Linas Vepstas January 2009

This directory contains some experimental code to extract "semantic
triples" from English text.  A semantic triple is a triple of 
subject-predicate-object, and is popularly the topic of "Semantic Web
RDF" technology discussions[WP-RDF].  An example of a "semantic triple"
is "the sky is blue". Written in prefix notation, the triple is then 
"color_of(sky, blue)", with "color_of" being the property or predicate,
while "sky" and "blue" are the subject and object, respectively. In the
industry, this task is sometimes refered to as "WIE" or "Web Information
Extraction"; it is also sometimes called "linguistic reification".

One reason for creating semantic triples is that it simplifies certain
types of deductions and inferences. For example, "author_of('Pride and 
Prejudice', 'Jane Austen')" and "wrote('Pride and Prejudice', 'Jane 
Austen')" are more or less synonymous expressions. Normalizing more
complex structures (such as the output of RelEx, or of dependency 
parsers in general), make it considerably easier to automatically
discover such synonymous expressions.

The primary challenge here is of dealing with the diversity of
expression in the English language, where most sentences are NOT short,
to-the-point assertions that something is true. For short, simple
sentences, ReLex seems to provide enough normalization to extract at
least some triples. But it is not clear how far this idea (of using
triples) can be pushed.

For the most part, the above challenge is ignored here; it is pursued
in greater detail in the nlp/seme/README. Instead, a more concrete set
of tasks are set out and solved here: 

1) How to represent semanctic triples within OpenCog.
2) How to extract basic semantic triples from straightforward, 
   unambiguous RelEx input.

The result is the defintion of an IF..THEN.. syntax that can be converted
to OpenCog ImplicationLinks, and then used (via the query system) to
process RelEx input and generate triples output.  The IF..THEN.. syntax
very closely resembles that used by the RelEx framing code, with the 
intention that someday, it will be possible to use this code to port the
RelEx frame processing to OpenCog.

Structures
----------
Triples are to follow the existing opencog predicate structure:

   (EvaluationLink
      (ConceptNode "color_of")
      (ListLink
         (ConceptNode "sky")
         (ConceptNode "blue")
      )
   )

is an example of what would be deduced from the copula "The color of the
sky is blue". This example is somewhat over-simplified; this is
addressed later.

Simples Example Sentences
-------------------------
First, consider some input sentences:

Input sentence: "The capital of Germany is Berlin."
Relex output: 
_subj(be, capital)
_obj(be, Berlin)
of(capital, Germany)

Input sentence: "Berlin is the capital of Germany."
_subj(be, Berlin)
_obj(be, capital)
of(capital, Germany)

Input sentence: "The color of the sky is blue."
of(color, sky)
_predadj(color, blue)

Input sentence: "Pottery is made from clay."
_obj(make, pottery)
from(make, clay)

Input sentence: "Yarn is spun from fibers."
_obj(spin, yarn)
from(spin, fibers)

Input sentence: "Yarn is made of fibers."
_obj(made_of, yarn)
_iobj(made_of, fibers)

Input sentence: "Berlin is in Germany."
The more highly ranked parse gives:
in(_%copula, in)
_pobj(in, Germany)
_psubj(in, Berlin)

A second, but lower-ranked parse, gives:
in(be, Germany)
_subj(be, Berlin)

Input sentence: "Berlin is a city in Germany."
in(be, Germany)
_subj(be, Berlin)
_obj(be, city)

A second, but lower-ranked parse, gives:
in(city, Germany)
_subj(be, Berlin)
_obj(be, city)

Clearly, even simple assertions have many different forms.

A prepositional modifier complicates things:
Input sentence: A chair is used for sitting on.

Modifiers can change the meaning:
Copper is a good conductor of electricity.
Glass is a bad conductor of electricity.

Cows eat grass.
A bird can fly.
A dog can be a pet.
A person wants love.
Some leaves are green.


A priori vs. Deduced Knowledge
------------------------------
Consider again the following:

_subj(be, capital)
_obj(be, Berlin)
of(capital, Germany)

This sentence references a lot of a-priori knowledge.  We know that
capitals are cities; thus there is a strong temptation to write a
processing rule such as "IF ($var0,capital) THEN ($var0,city)".
Similarly, one has a-priori knowledge that things which have capitals
are political states, and so one is tempted to write a rule asserting
this: "IF (capital_of($var0, $var1)) THEN political_state($var1)".

A current working assumption of what follows is that the normalization
rules will attempt to encode a minimum of a-priori "real-world" knowledge.
Instead, the goal here is to encode linguistic knowledge, and
specifically, linguistic knowledge pertaining to prepositions and
copulas: the copula expresses "is-a" relations, while the preposition
expresses relationships: "has-a", "next-to", "part-of", "made-of", etc.

The hope is that, by encoding the relatively small number of
prepositional relationships, the much larger set of "real-world"
knowledge rules can be deduced (via backward or forward chaining).

Definite vs. Indefinite
-----------------------
There is a subtle semantic difference between triples that describe
definite properites, vs. triples that describe generic properities,
or semantic classes.  Thus, for example, "color_of(sky,blue)" seems 
unambiguous: this is because we know that the sky can only ever have
one color (well, unless you are looking at a sunset!). Consider 
"form_of(clothing, skirt)": this asserts that a skirt is a form_of
clothing, and not that clothing is always a skirt. The form_of
indicates a semantic category.  Similarly, "group_of(people, family)"
asserts that a family is a group_of people, and not that groups of
people are families.

The distinction here seems to be whether or not the modifier was
definite or indefinite: "THE color of ...." vs. "A form of.." or
"A group of..."

XXX This is a real bug/hang-up in the triples processing code: 
being unaware of this distinction seems to cause some triples
to come out "backwards" (i.e. that clothing is always a skirt).
Caution to be used during seme formation!


Rules
-----
Consider again the following:

   Input sentence: "The capital of Germany is Berlin."
   _subj(be, capital)
   _obj(be, Berlin)
   of(capital, Germany)

and we wish to deduce:

   captial_of(Germany, Berlin)

The following processing rule acheives this:

   # IF _subj(be,$var0) ^ _obj(be,$var1) ^ $prep($var0,$var2) THEN 
     ^3_$var0_$prep($var2, $var1)

The carats ^ in the pedicate denote 'and'. Dollar signs preceed variable
names. In the predicand, the initial ^3_ denotes the origin of the rule.
(^1_ denoes framenet, ^2_ denoes David Noziglia, and ^3_ deones Linas).
The above IF-THEN rule is intended to be identical in syntax to the
rules that are already used in the RelEx framing code; i.e. the syntax
is meant to be identical to that of the file "data/frame/mapping_rules.txt"
in the RelEx source tree.

The ! symbol denotes "not". Used in front of a term, it states that the
term must be *absent*, or, if present, must have a truth value of 'false'.
See the section "is-a", below, for an example usage.

The above rule cannot be applied to the following:

   Input sentence: "Berlin is the capital of Germany."
   _subj(be, Berlin)
   _obj(be, capital)
   of(capital, Germany)

because of the constraint that $var0 appear in both the preposition
and the subject.  Proper mangling of the above requires the following
rule:

   # IF _subj(be,$var0) ^ _obj(be,$var1) ^ $prep($var1,$var2) THEN 
     ^3_$var1_$prep($var2, $var0)

Notice the connection across var0 and var1 is symmetrically exchanged.


Representing IF...THEN constructs in OpenCog
============================================
The core idea is to find patterns in text, and then create new patterns
as a result. As the simplest example, a "pattern" would be finding all
instances of a noun in some block of text, assuming that all of these
nouns refer to the same thing, and so creating a ConceptNode that
encompases all of these noun instances.  This can be crudely represented
as the pseudo-code:

   IF (for-all parses of all sentences in same document)
       AND (word-instance-1 == noun)
       AND (word-of-word-instance-2 == word-of-word-instance-1)
       AND ...
       AND (word-of-word-instance-k == word-of-word-instance-1)
   THEN (create concept-node encompassing word-instances 1 thru k)

It would be "easiest" to code up above in C++ or Scheme (or Java or
Python or ...) but this missses the point: The opencog system will
need to be able to modify the above rule (or algorithm) based on
learned, statistical experience, for example, by adding more
AND-clauses to refine the action.

Another example: The consistency of this reference assignment can be
checked using the following pseudo-code:

   IF (word-instance-1 is-grouped-wth word-instance-2 in same concept)
      AND (word-instance-1 has property-A)
      AND (word-instance-2 has property-B)
      AND (property-A is inconnsistent with property-B)
   THEN (word-instance-1 and word-instance-2 should be ungrouped,
        and are probably distinct concepts)

The above pseudocode would help resolve text such as "Jurate held a red
balloon. Kastytis held a green balloon." The intitial reference
resolution would assign both word instances to the same object-instance
(i.e. assume that both words refer to just one balloon). The consistency
checker would note that the the color property is inconsistent, and thus
conclude that these are probably not refering to the same object. (And
tus, the combined-concept should be assigned a truth value close to
"false", and two new, distinct object-instance-concepts should be
created.

The core OpenCog nodes and links to be used to represent such rules are:
   VariableNode  -- to indicate a variable
   ImplicationLink -- to represent an if..then.. relationship.

Below is an example of the use of the ImplicationLink.

   "If the case is near the mouse and the cat is hungry, the cat will
   eat the mouse".

   ImplicationLink
   ___ANDLink
   ______ Inheritance $var0 cat
   ______ Inheritance $var0 hungry
   ______ EvaluationLink
   ___________ Node near
   ___________ ListLink
   _______________VariableNode $var1
   _______________VariableNode $var0
   ______ InheritanceLink $var1 mouse
   ___EvaluationLink
   ______Node eat
   ___________VariableNode $var0
   ___________VariableNode $var1


In practical terms, as the above shows, the encoding of rules will
likely be quite verbose. For the next example, consider two word
instances, using the current RelEx output format.

In the following, we will use the word "axiom" for "rule".
Each such rule has the structure of an implication, in Skolemized form,
with a list of variables up front, an antecedent (the "if" clause),
and a consequent (the "then" clause).  The antecedent is a list of
clauses that must be satisfied, the consequent is a set of nodes to
be created/modified.

   (VariableScopeLink
      ; A list of the variables in the "rule" or "axiom".
      ; This list essentially acts as a type declaration for
      ; the variables in this axiom.
      (ListLink
         ; Type declaration: $word-inst-0 is a word instance
         (WordInstanceNode $word-inst-0)
         (WordInstanceNode $word-inst-1)
         (ParseNode $parse-0)
         (ParseNode $parse-1)
         (SentenceNode $sentence-0)
         (SentenceNode $sentence-1)
         (DocumentNode $document)
         (ConceptNode $concept)

         ; The variable $word *must* be a WordNode
         (WordNode $word)
      )

      ; What follows is a conjunction of expressions
      ; that must be satisfied for this "axiom" to hold.
      (AndLink

         ; The word-instance must be nouns.
         (PartOfSpeechLink
            (VariableNode $word-inst-0)
            (DefinedLinguisticConceptNode "noun")
         )
         (PartOfSpeechLink
            (VariableNode $word-inst-1)
            (DefinedLinguisticConceptNode "noun")
         )

         ; The word-instances must refer to the same word.
         (LemmaLink
            (VariableNode $word-inst-0)
            (VariableNode $word)
         )
         (LemmaLink
            (VariableNode $word-inst-1)
            (VariableNode $word)
         )

         ; The word-instances must belong to the same document.
         ; This is done by making sure that they belong to parses,
         ; which belong to sentences, which belong to documents.
         ;
         ; XXX to-do: the number of words in a sentence is variable.
         ; Its not clear how to match this, given the structure below!
         (ReferenceLink
            (ParseNode $parse-0)
            (ListLink
               (VariableNode $word-inst-0)
            )
         )
         (ParseLink
            (ParseNode $parse-0)
            (SentenceNode $sentence-0)
         )
         (ReferenceLink
            (ParseNode $parse-1)
            (ListLink
               (VariableNode $word-inst-1)
            )
         )
         (ParseLink
            (ParseNode $parse-1)
            (SentenceNode $sentence-1)
         )
         (ReferenceLink
            (DocumentNode $document)
            (ListLink
               (SentenceNode $sentence-0)
               (SentenceNode $sentence-1)
            )
         )
      ) ; end of AndLink (the antecedent, or "if" clause)
      ; Above is the conjunction of clauses that must hold

      ; Next the consequent, or "then" clause.
      ; Create a single concept, which encompases each of these word
      ; instances, implying that they all refer the to same overall
      ; concept.

      ; XXX somehow generate a new UUID for this new concept!
      ; use a combo tof the word, and the document, to help identify it.
      (ConceptNode $concept)
      (ExtensionalInheritanceLink
         (ConceptNode $concept)
         (WordInstanceNode $word-inst-0)
      )
      (ExtensionalInheritanceLink
         (ConceptNode $concept)
         (WordInstanceNode $word-inst-1)
      )
   )


Evaluator, Application of Rules
================================
The above-described "rules" or "templates" perform transformations on
hypergraphs. There needs to be an "apply" function to apply these rules
to document hypergraphs. Here, "Apply" is meant to have the usual
comp-sci overtones of function application, see, for example, the
Wikipedia article, or SICP chapter 4.  There are several ways in which
the "apply" function might  be implemented.
  
Possibilities:
1) Make use of PLN forward or backward chainers to perform the
   application.
2) Adapt existing "src/query" code, which does general pattern matching,
   (i.e. is capable of matching to VariableNodes) to be able to apply
   above rules.

At this time, the foreward & backwards chainers are designed for a
slightly different purpose; they are not really meant to be a generic
"Apply" function. They are also missing several syntactical constructs
needed for "apply" to work:

  a) Ability to declare the type of a variable (The core assumption here
     is that OpenCog should be a strongly-typed langauge)
  b) The inability to create new atoms and links, as needed.

On the other side, the chainers do correctly propagate truth values;
whereas the query code is truth-value agnostic.  Open question: XXX How
should the Apply function handle truth values?

XXX While we're at it: should define a lambda. This would make
everything *sooo* much easier. Note that the chainers do not have
support for lambda at this time.


Encoding as an ImplicationLink
------------------------------
The above rules are to be encoded as ImplicationLinks. Thus, the rule

   # IF _subj(be,$var0) ^ _obj(be,$var1) ^ $prep($var0,$var2) THEN 
     ^3_$var0_$prep($var2, $var1)

is meant to be a short-hand for:

   ImplicationLink
      AndLink
         EvaluationLink
            DefinedLinguisticRelationshipNode "_subj"
            ListLink
               ConceptNode "be"
               VariableNode "$var0"
         EvaluationLink
            DefinedLinguisticRelationshipNode "_obj"
            ListLink
               ConceptNode "be"
               VariableNode "$var1"
         EvaluationLink
            VariableNode "$prep"
            ListLink
               VariableNode "$var0"
               VariableNode "$var2"
      EvaluationLink
         DefinedLinguisticRelationshipNode ($var0 . "_" . $prep)
         ListLink
            VariableNode "$var2"
            VariableNode "$var1"

Note the snag of concatenating strings.  The only easy way out of
this appears to be to salt the atomspace with contractions.  Thus,
the atomspace would contain a relation:

   EvaluationLink
      DefinedLinguisticRelationshipNode "capital_of"
      ListLink
         ConceptNode "capital"
         DefinedLinguisticRelationshipNode "of"

The above ImplicationLink would then include a fourth clause in the
predicate:

   EvaluationLink
      VariableNode $phrase
      ListLink
         VariableNode $var0
         VariableNode $prep

while the implicand would be written as:

   EvaluationLink
      VariableNode $phrase
      ListLink
         VariableNode "$var2"
         VariableNode "$var1"

The above would be expressed directly in the rules syntax as:

   # IF _subj(be,$var0) ^ _obj(be,$var1) ^ $prep($var0,$var2) 
       ^ $phrase($var0, $prep)
       THEN ^3_$phrase($var2, $var1)

There is one additional complication to the above. The natural output of
Relex puts a buffer between words and concepts. Thus, and example of the 
output is:

(EvaluationLink
   (DefinedLinguisticRelationshipNode "of")
   (ListLink
      (WordInstanceNode "capital@cd67b274-9957-463c-aad8-422bec133613")
      (WordInstanceNode "Germany@75f2f934-91a7-47ba-9bcc-e2a3340c9076")
   )
)

The word instances are related to thier lemmatized forms:

(LemmaLink
   (WordInstanceNode "capital@cd67b274-9957-463c-aad8-422bec133613")
   (WordNode "capital")
)
(LemmaLink
   (WordInstanceNode "Germany@75f2f934-91a7-47ba-9bcc-e2a3340c9076")
   (WordNode "Germany")
)

Thus, the implication predicate needs to bind word-instances to word
nodes. 

There is another problem: ImplicationLinks cannot be used to change 
the type of a node. Thus, while the examples above made reference to
ConceptNodes, the actual RelEx LemmaLinks specify WordNodes.  There's 
no immediate, direct way to turn WordNodes into ConceptNodes; this 
will be fudged for now.

Another problem to note: it only makes sense to extract relations
between words in a sentence (or across sentences, if reference resolution
is implemented).  However, there is currently no natural way to specify
that the searches should be performed only on a certain subset of the
atom space -- e.g. to perform the matching only on terms that belong to 
one sentence.  Thus, at this time, each frame rule contains explicit
directives that force all matches to lie within one sentence. So, for
example:

# IF _subj(be,$var0) ^ _obj(be,$var1)
      ^ $prep($var0,$var2)              ; preposition 
      ^ %LemmaLink($var0,$word0)        ; word of word instance
      ^ $phrase($word0, $prep)          ; convert to phrase
      ^ %WordInstanceLink($var0,$sent)  ; $var0 and $var1 must be
      ^ %WordInstanceLink($var1,$sent)  ; in the same sentence
      THEN ^3_$phrase($var2, $var1) 

Note the use of WordInstanceLink to force both words to belong to 
the same sentence.


Demonstration run
-----------------
The file "rules.txt" contains the current set of rules.  The perl script
"rules-to-implications.pl" will convert rules into OpenCog 
ImplicationLinks, as described above. 

The shell script "load.sh" in this directory will load the assorted
scheme bits and pieces.  In addition, text that was parsed by relex,
and output in opencog format, must be loaded, using "load-examples.sh".

Sentences must be pre-processed by running the following:
   (cog-ad-hoc "do-implication" prep-rule-0)
and again for prep-rule 1,2,3 inclusive.

Implications can be processed with the scheme interpreter, using the 
ad-hoc command:

  (cog-ad-hoc "do-implication" stmt)

where the stmt is the implication to evaluate. So, for example, after
loading rules.txt, (and starting at the 5th rule -- the first 4
perform some setup) one would try:

  (cog-ad-hoc "do-implication" frame-rule-0)

This will search the entire contents of the atomtable, looking for any
hypergraphs that match the predicate of the implication.  The output is
a list of all possible implicands: thus, for example:

guile> (cog-ad-hoc "do-implication" frame-rule-0)
(ListLink (EvaluationLink (DefinedLinguisticRelationshipNode "capital_of")
    (ListLink (WordInstanceNode "Germany@3cdca1f8-adf4-4532-a2d6-622da3f43ce6")
       (WordInstanceNode "Berlin@a0d168f7-3735-48a1-b603-33dd0fc95228"))))

guile> (cog-ad-hoc "do-implication" frame-rule-1)
(ListLink (EvaluationLink (DefinedLinguisticRelationshipNode "capital_of")
    (ListLink (WordInstanceNode "Portugaul@36d41058-3dc8-4e6c-82b9-300a5f48e283")
       (WordInstanceNode "Lisbon@9d5031b1-5caf-48eb-ae7c-b3a89bb11381"))))

guile> (cog-ad-hoc "do-implication" frame-rule-2)
(ListLink (EvaluationLink (DefinedLinguisticRelationshipNode "color_of")
    (ListLink (WordInstanceNode "sky@f3924dad-81a0-4967-81c8-900e31254f74")
       (WordInstanceNode "blue@df54a7e9-1fb2-4643-be97-ca6ee1e7a359"))))

Note that the rule numbering is subject to change; more setup rules
might be added.


IsA Sentences
-------------
Copulas, and "is-a" sentences in general, pose difficulties to naive
approaches of extracting is-a relations from text.  This section
examines some of these difficulties, and possible solutions.

Consider, for example: "Berlin is a city"
   _subj(be, Berlin)
   _obj(be, city)

Which suggests the deduction: _isa(city, Berlin) which can be produced by

# IF _subj(be, $var1) ^ _obj(be, $var2) THEN ^3_isa($var2, $var1)

However, the sentence: "The captial of Germany is Berlin.", when parsed,
has the subject and object in reverse order, and so, when this rule is
applied, returns a backwards IsA relation ('capital is a berlin'). The
preposition "of" signals the subect-object inversion; but also, the 
determiners clash for an is-a ('the capital is the berlin') -- we expect
the sentence patterns "x is a y" or "x is the y of ..." but not a naked
"x is the y".

   "Berlin is a city"
      DEFINITE-FLAG(Berlin, T)
      noun_number(Berlin, singular)
      noun_number(city, singular)
      _subj(be, Berlin)
      _obj(be, city)

   "The capital of Germany is Berlin."

      DEFINITE-FLAG(Germany, T)
      noun_number(Germany, singular)
      of(capital, Germany)
      DEFINITE-FLAG(capital, T)
      noun_number(capital, singular)
      DEFINITE-FLAG(Berlin, T)
      noun_number(Berlin, singular)
      _subj(be, capital)
      _obj(be, Berlin)

Ignoring the prepositional parts, we get:

      DEFINITE-FLAG(capital, T)
      noun_number(capital, singular)
      DEFINITE-FLAG(Berlin, T)
      noun_number(Berlin, singular)
      _subj(be, capital)
      _obj(be, Berlin)

This suggests that the correct rule for is-a relations is:

   # IF _subj(be, $var1) ^ _obj(be, $var2) 
       ^ !DEFINITE-FLAG($var2)
       THEN ^3_isa($var2, $var1)

The ! in front of DEFINITE-FLAG means "not" or "invert"; the 
DEFINITE-FLAG must be absent, or, if present, must be false.
Note that all top-level clauses (subj, obj, etc.) must have truth
values set so that they're true. This is because the truth value
is examined to compute the effect of !. The default truth value
in Opencog is (false, unconfident), so it must be over-ridden
to state (true, confident).

Another case where we must be careful is with hypothetical statements
or questions that superficially resemble statements. For example, the 
question: "Is Berlin a capital?" parses out to:

   _subj (be, Berlin) 
   _obj (be, capital) 
   TRUTH-QUERY-FLAG (capital, T)
   TRUTH-QUERY-FLAG (be, T)
   HYP (be, T)

If the truth-query and hyp flags are ignored, then this parse can be
mistaken for a statement, not a question.  This suggests that the rules
should includee a !HYP term in them.



Consider now: "Men are mortal."
   _predadj(men, mortal)

which suggests the rule:

 # IF _predadj($var1, $var2) THEN ^3_isa($var2, $var1)

However, prepositions again confound word order:
Input sentence: "The color of the sky is blue."
   of(color, sky)
   _predadj(color, blue)

By ignoring the preposition, the sentence becomes: "color is blue", 
i.e. that 'colors' are a kind-of blue, which is inverted from the 
intended sense. The next-most naive rule is then:

  # IF _predadj($var1, $var2) ^ 
       ! $prep($var1,$var3)
       THEN ^3_isa($var2, $var1)

and also the inverted word-order case:

  # IF _predadj($var1, $var2) ^ 
       $prep($var1,$var3)
       THEN ^3_isa($var1, $var2)

XXX However, this doesn't quite work because  $prep($var2,$var3) is
so broad, that it can match to just about anything, including things
are not DefinedLinguisticRelationship nodes. Thus, we need to force
type matching in variables.

Other problems: Consider the sentences:
"A hospital is a place where you go when you are sick."

One may deduce that "A hospital is a place", but one must be careful
in making use of such knowledge....


Yes-No Questions
----------------
Question:
    Is Berlin a capital?

Parse:
   _subj (be, Berlin) 
   _obj (be, capital) 
   TRUTH-QUERY-FLAG (capital, T)
   TRUTH-QUERY-FLAG (be, T)
   HYP (be, T)


HOWTO
-----
How to run the current code in example/demo/debug mode:
-- start cog-server
-- run load.sh
-- run load-examples.sh  to load the example sentences.
-- Enter the scheme shell
-- run (cog-ad-hoc "do-implication" prep-rule-0) through
   (cog-ad-hoc "do-implication" prep-rule-3) 
   These is a require step to perform some initial setup.
-- run (cog-ad-hoc "do-implication" frame-rule-0) through
   (cog-ad-hoc "do-implication" frame-rule-9) and observe results.

Next step:
-- Download the MIT ConceptNet corpus.
-- This corpus is in N3 format; strip out sentences by 
   running "conceptnet.pl"
-- Parse the sentences using relex, generate opencog output.
   (There are about 252870 sentences in the June 2008 dump.)
-- Create a presistence repository for accumulating results.
   (at this time, create a new SQL db)
       createdb triples
       cat opencog/persist/atom.sql | psql triples
-- Run cogserver
-- open the database created above
-- Edit nlp/seme/config.scm and change file patch to parsed sentences.
   xx xx move these docs to the seme directory
-- run load.sh
-- Enter the scheme shell

XXXXXXXXXXXXXX TEMPORARILY BROKEN, input sentences must be linked to
AnchorNode "# APPLY TRIPLE RULES" via list link to apply.

-- run command (do-triples n) where n is the number of files
   to process.

Alternately, load data in some other way, and then
issues the scheme expression (fire-all-triple-rules) to create
the assorted triples.


Notes
-----
6:38 to load part 1 (3693 sentences)
5:33 to load part 1
6:51 to load part 1
0:30 to create prep maps in bulk
first threee take <1min each.
4th took 18 mins
rest took < 1min
27:04 including the load time. to process 3693 sentences.
This lead to 3841 rows.

alt: sentence at a time: 13:18 total time.

part 2: start at 17:02 end 17:53 elapsed time =51 minutes w/ 18 mins
cpu time.

part 3: start 10:25 end 10:58 elapsed=33 mins w/ 10:56 cpu time.


References:
-----------
[APPL] Apply: See
   http://en.wikipedia.org/wiki/Apply
   Also, Abelson, Sussman, SICP, section 4.1 the Meta-circular evaluator
   http://mitpress.mit.edu/sicp/full-text/book/book-Z-H-26.html

[IMPL] Implication: See
   http://en.wikipedia.org/wiki/Logical_implication

[WP-RDF] Resource Description Framework
     http://en.wikipedia.org/wiki/Resource_Description_Framework

Alexander Yates and Oren Etzioni.
[http://www.cis.temple.edu/~yates/papers/resolver-jair09.pdf
Unsupervised Methods for Determining Object and Relation Synonyms on
the Web]. Journal of Artificial Intelligence Research 34, March,
2009, pages 255-296.

