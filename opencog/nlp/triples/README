
                                   Triples
                                   -------
                         Linas Vepstas January 2009

This directory contains some experimental code to extract conceptual 
entities and semantic triples from English text.  An example of a 
"conceptual entity" would be the "Great Southern Railroad": a business,
a railway, that existed at a certain point in space and time. A semantic
triple is a triple of subject-predicate-object, and is popularly the 
topic of "Semantic Web RDF" technology discussions[WP-RDF].  An example 
of a "semantic triple" is "the sky is blue". Written in prefix notation,
the triple is then "color_of(sky, blue)", with "color_of" being the
property or predicate, while "sky" and "blue" are the subject and
object, respectively.

One reason for creating semantic triples is that it simplifies certain
types of deductions and inferences. For example, "author_of('Pride and 
Prejudice', 'Jane Austen')" and "wrote('Pride and Prejudice', 'Jane 
Austen')" are more or less synonymous expressions. Normalizing more
complex structures (such as the output of RelEx, or of dependency 
parsers in general), make it considerably easier to automatically
discover such synonymous expressions.

The primary challenges here are three-fold:
1) Dealing with the diversity of expression in the English language, 
   where most sentences are NOT short, to-the-point assertions that
   something is true. For short, simple sentences, ReLex seems to
   provide enough normalization to extract at least some triples. But 
   it is not clear how far this idea (of using triples) can be pushed.
2) Learning new relations. It is simple to code up, by hand, "framing"
   relationships, such as a list of colors, or a list properties that
   an object can have. It is harder to determine, when encountering a 
   new word, to determine that it is, for example, a color.
3) Constructing a data representation that is ameanable to reasoning,
   and to question answering. 

ToDo: Reification of triples ... 
Phrasal verbs vs. prepositional phrases 

Structures
----------
Triples are to follow the existing opencog predicate structure:

   (EvaluationLink
      (ConceptNode "color_of")
      (ListLink
         (ConceptNode "sky")
         (ConceptNode "blue")
      )
   )

is an example of what would be deduced from the copula "The color of the
sky is blue". This example is somewhat over-simplified; this is
addressed later.

Simples Example Sentences
-------------------------
First, consider some input sentences:

Input sentence: "The capital of Germany is Berlin."
Relex output: 
_subj(be, capital)
_obj(be, Berlin)
of(capital, Germany)

Input sentence: "Berlin is the capital of Germany."
_subj(be, Berlin)
_obj(be, capital)
of(capital, Germany)

Input sentence: "The color of the sky is blue."
of(color, sky)
_predadj(color, blue)

Input sentence: "Pottery is made from clay."
_obj(make, pottery)
from(make, clay)

Input sentence: "Yarn is spun from fibers."
_obj(spin, yarn)
from(spin, fibers)

Input sentence: "Yarn is made of fibers."
_obj(made_of, yarn)
_iobj(made_of, fibers)

Input sentence: "Berlin is in Germany."
The more highly ranked parse gives:
in(_%copula, in)
_pobj(in, Germany)
_psubj(in, Berlin)

A second, but lower-ranked parse, gives:
in(be, Germany)
_subj(be, Berlin)

Input sentence: "Berlin is a city in Germany."
in(be, Germany)
_subj(be, Berlin)
_obj(be, city)

A second, but lower-ranked parse, gives:
in(city, Germany)
_subj(be, Berlin)
_obj(be, city)

Clearly, even simple assertions have many different forms.

A prepositional modifier complicates things:
Input sentence: A chair is used for sitting on.

Modifiers can change the meaning:
Copper is a good conductor of electricity.
Glass is a bad conductor of electricity.

Cows eat grass.
A bird can fly.
A dog can be a pet.
A person wants love.
Some leaves are green.


A priori vs. Deduced Knowledge
------------------------------
Consider again the following:

_subj(be, capital)
_obj(be, Berlin)
of(capital, Germany)

This sentence references a lot of a-priori knowledge.  We know that
capitals are cities; thus there is a strong temptation to write a
processing rule such as "IF ($var0,capital) THEN ($var0,city)".
Similarly, one has a-priori knowledge that things which have capitals
are political states, and so one is tempted to write a rule asserting
this: "IF (capital_of($var0, $var1)) THEN political_state($var1)".

A current working assumption of what follows is that the normalization
rules will attempt to encode a minimum of a-priori "real-world" knowledge.
Instead, the goal here is to encode linguistic knowledge, and
specifically, linguistic knowledge pertaining to prepositions and
copulas: the copula expresses "is-a" relations, while the preposition
expresses relationships: "has-a", "next-to", "part-of", "made-of", etc.

The hope is that, by encoding the relatively small number of
prepositional relationships, the much larger set of "real-world"
knowledge rules can be deduced (via backward or forward chaining).

Learning Semantic Categories
----------------------------
Consider the category of "types of motion". Currently, the RelEx frame
rules include an explicit list of category members:  

$Self_motion
amble
bustle
canter
clamber
climb
clomp
coast
crawl
creep

This list clearly encodes a-priori knowledge about locomotion.  It would
be better if the members of this category could be deduced by reading.
There are three ways in which this might be done. One might someday
read a sentence that asserts "Crawling is a type of locomotion".  This
seems unlikely, as this is common-sense knowledge, and common-sense
knowledge is not normally encoded in text. A second possibility is to
learn the meaning of the word "crawl" the way that children learn it: 
to have someone point at a centipede and say "gee, look at that thing
crawl!"  Such experiential, cross-sensory learning would indeed be an
excellent way to gain new knowledge. However, there are two snags: 
1) It presumes the existence of a teacher who already knows how to use
the word "crawl", and 2) It is outside of the scope of what one person
(i.e. me) can acheive in a limited amount of time.  A third possibility
is statistical learning: to observe a large number os statements
containing the word "crawl", and, based on these, deduce that it is a
type of locomotion.

In the following, the third approach is presumed. This is because the
author has in hand both the statistical and the linguistic tools that
would allow such observation and deduction to be made.

Rules
-----
Consider again the following:

   Input sentence: "The capital of Germany is Berlin."
   _subj(be, capital)
   _obj(be, Berlin)
   of(capital, Germany)

and we wish to deduce:

   captial_of(Germany, Berlin)

The following processing rule acheives this:

   # IF _subj(be,$var0) ^ _obj(be,$var1) ^ $prep($var0,$var2) THEN 
     ^3_$var0_$prep($var2, $var1)

The carats ^ in the pedicate denote 'and'. Dollar signs preceed variable
names. In the predicand, the initial ^3_ denotes the origin of the rule.
(^1_ denoes framenet, ^2_ denoes David Noziglia, and ^3_ deones Linas).
The above IF-THEN rule is intended to be identical in syntax to the
rules that are already used in the RelEx framing code; i.e. the syntax
is meant to be identical to that of the file "data/frame/mapping_rules.txt"
in the RelEx source tree.

The ! symbol denotes "not". Used in front of a term, it states that the
term must be *absent*, or, if present, must have a truth value of 'false'.
See the section "is-a", below, for an example usage.

The above rule cannot be applied to the following:

   Input sentence: "Berlin is the capital of Germany."
   _subj(be, Berlin)
   _obj(be, capital)
   of(capital, Germany)

because of the constraint that $var0 appear in both the preposition
and the subject.  Proper mangling of the above requires the following
rule:

   # IF _subj(be,$var0) ^ _obj(be,$var1) ^ $prep($var1,$var2) THEN 
     ^3_$var1_$prep($var2, $var0)

Notice the connection across var0 and var1 is symmetrically exchanged.


Encoding as an ImplicationLink
------------------------------
The above rules are to be encoded as ImplicationLinks. Thus, the rule

   # IF _subj(be,$var0) ^ _obj(be,$var1) ^ $prep($var0,$var2) THEN 
     ^3_$var0_$prep($var2, $var1)

is meant to be a short-hand for:

   ImplicationLink
      AndLink
         EvaluationLink
            DefinedLinguisticRelationshipNode "_subj"
            ListLink
               ConceptNode "be"
               VariableNode "$var0"
         EvaluationLink
            DefinedLinguisticRelationshipNode "_obj"
            ListLink
               ConceptNode "be"
               VariableNode "$var1"
         EvaluationLink
            VariableNode "$prep"
            ListLink
               VariableNode "$var0"
               VariableNode "$var2"
      EvaluationLink
         DefinedLinguisticRelationshipNode ($var0 . "_" . $prep)
         ListLink
            VariableNode "$var2"
            VariableNode "$var1"

Note the snag of concatenating strings.  The only easy way out of
this appears to be to salt the atomspace with contractions.  Thus,
the atomspace would contain a relation:

   EvaluationLink
      DefinedLinguisticRelationshipNode "capital_of"
      ListLink
         ConceptNode "capital"
         DefinedLinguisticRelationshipNode "of"

The above ImplicationLink would then include a fourth clause in the
predicate:

   EvaluationLink
      VariableNode $phrase
      ListLink
         VariableNode $var0
         VariableNode $prep

while the implicand would be written as:

   EvaluationLink
      VariableNode $phrase
      ListLink
         VariableNode "$var2"
         VariableNode "$var1"

The above would be expressed directly in the rules syntax as:

   # IF _subj(be,$var0) ^ _obj(be,$var1) ^ $prep($var0,$var2) 
       ^ $phrase($var0, $prep)
       THEN ^3_$phrase($var2, $var1)

There is one additional complication to the above. The natural output of
Relex puts a buffer between words and concepts. Thus, and example of the 
output is:

(EvaluationLink
   (DefinedLinguisticRelationshipNode "of")
   (ListLink
      (WordInstanceNode "capital@cd67b274-9957-463c-aad8-422bec133613")
      (WordInstanceNode "Germany@75f2f934-91a7-47ba-9bcc-e2a3340c9076")
   )
)

The word instances are related to thier lemmatized forms:

(LemmaLink
   (WordInstanceNode "capital@cd67b274-9957-463c-aad8-422bec133613")
   (WordNode "capital")
)
(LemmaLink
   (WordInstanceNode "Germany@75f2f934-91a7-47ba-9bcc-e2a3340c9076")
   (WordNode "Germany")
)

Thus, the implication predicate needs to bind word-instances to word
nodes. 

There is another problem: ImplicationLinks cannot be used to change 
the type of a node. Thus, while the examples above made reference to
ConceptNodes, the actual RelEx LemmaLinks specify WordNodes.  There's 
no immediate, direct way to turn WordNodes into ConceptNodes; this 
will be fudged for now.

Another problem to note: it only makes sense to extract relations
between words in a sentence (or across sentences, if reference resolution
is implemented).  However, there is currently no natural way to specify
that the searches should be performed only on a certain subset of the
atom space -- e.g. to perform the matching only on terms that belong to 
one sentence.  Thus, at this time, each frame rule contains explicit
directives that force all matches to lie within one sentence. So, for
example:

# IF _subj(be,$var0) ^ _obj(be,$var1)
      ^ $prep($var0,$var2)              ; preposition 
      ^ %LemmaLink($var0,$word0)        ; word of word instance
      ^ $phrase($word0, $prep)          ; convert to phrase
      ^ %WordInstanceLink($var0,$sent)  ; $var0 and $var1 must be
      ^ %WordInstanceLink($var1,$sent)  ; in the same sentence
      THEN ^3_$phrase($var2, $var1) 

Note the use of WordInstanceLink to force both words to belong to 
the same sentence.


Demonstration run
-----------------
The file "rules.txt" contains the current set of rules.  The perl script
"rules-to-implications.pl" will convert rules into OpenCog 
ImplicationLinks, as described above. 

The shell script "load.sh" in this directory will load the assorted
scheme bits and pieces.  In addition, text that was parsed by relex,
and output in opencog format, must be loaded, using "load-examples.sh".

Implications can be processed with the scheme interpreter, using the 
ad-hoc command:

  (cog-ad-hoc "do-implication" stmt)

where the stmt is the implication to evaluate. So, for example, after
loading rules.txt, (and starting at the 5th rule -- the first 4
perform some setup) one would try:

  (cog-ad-hoc "do-implication" frame-rule-4)

This will search the entire contents of the atomtable, looking for any
hypergraphs that match the predicate of the implication.  The output is
a list of all possible implicands: thus, for example:

guile> (cog-ad-hoc "do-implication" frame-rule-4)
(ListLink (EvaluationLink (DefinedLinguisticRelationshipNode "capital_of")
    (ListLink (WordInstanceNode "Germany@3cdca1f8-adf4-4532-a2d6-622da3f43ce6")
       (WordInstanceNode "Berlin@a0d168f7-3735-48a1-b603-33dd0fc95228"))))

guile> (cog-ad-hoc "do-implication" frame-rule-5)
(ListLink (EvaluationLink (DefinedLinguisticRelationshipNode "capital_of")
    (ListLink (WordInstanceNode "Portugaul@36d41058-3dc8-4e6c-82b9-300a5f48e283")
       (WordInstanceNode "Lisbon@9d5031b1-5caf-48eb-ae7c-b3a89bb11381"))))

guile> (cog-ad-hoc "do-implication" frame-rule-6)
(ListLink (EvaluationLink (DefinedLinguisticRelationshipNode "color_of")
    (ListLink (WordInstanceNode "sky@f3924dad-81a0-4967-81c8-900e31254f74")
       (WordInstanceNode "blue@df54a7e9-1fb2-4643-be97-ca6ee1e7a359"))))

Note that the rule numbering is subject to change; more setup rules
might be added.


Promoting Words to Concepts
---------------------------
There is one more aspect to this, which is much deeper: the promotion
of word-relations to concepts.  Consider the following relationships:

   is_a(bark, sound)
   part_of(bark, tree)

We know that these two relations refer to different senses of the word
"bark". Yet, if these two are deduced by reading, how should the system
recognize that two different concepts are at play?  How should the
self-consistency of a set of relations be assessed? Assuming that the
input text is not intentionally lying, then, under what circumstances
do a set of conflicting assertions require that the underlying word be
recognized as embodying two different concepts?

Several approaches are possible:
1) Assign tentative word-senses via the Mihalcea algorithm.
   Unfortunately, this algorithm is quite slow.  This can be partly
   worked around using the syntax-tagged senses taken from a database.
   This is extremely fast, however, its not terribly accurate; nor is
   the Mihalcea algorithm all that accurate either.  None-the-less
   its a reasonable starting point, perhaps.

2) Verify consistency via first-order-logic and forward/backward
   chaining. This has several difficulties. One is the problem of
   performance, and bounding the search space. Another is that, if
   an inconsistency is detected, its still not clear what faulty
   assumption lead to it.  There is no algorithm for classifying 
   a set of conflicting statements into two groups of self-consistent
   statements.

   (Possibly need to re-examin Markov Logic Networks?)

Consistency Checking
--------------------
Consider the following three sentences:
   Aristotle is a man.
   Men are mortal.


   Berlin is the capital of Germany.
   Capitals are cities.
   Berlin is a city.

Assume the first two sentences were previously determined to be true,
with a high confidence value. How can we determine that the third 
sentence is plausible, i.e. consistent with the first two sentences?

Upon reading the third sentence, it could be turned into a hypothetical
statement, and suggested as the target of the PLN backward chainer. If
the chainer is able to deduce that it is true, then the confidence of
all three statements can increase: they form a set of mutually
self-supporting statements.

So, for example, the above generate:
   capital_of(Germany,Berlin)
   isa(city, capital)
   isa(city, Berlin)

The prepositional construction XXX_of(A,B) allows the deduction that
isa(XXX,A) (a deduction which can be made directly from the raw sentence
input, and does not need to be processed from the prepositional form.
(Right??) Certainly this is true for kind_of and capital_of, is this
true for all prepositional uses of "of"?

IsA Sentences
-------------
Copulas, and "is-a" sentences in general, pose difficulties to naive
approaches of extracting is-a relations from text.  This section
examines some of these difficulties, and possible solutions.

Consider, for example: "Berlin is a city"
   _subj(be, Berlin)
   _obj(be, city)

Which suggests the deduction: _isa(city, Berlin) which can be produced by

# IF _subj(be, $var1) ^ _obj(be, $var2) THEN ^3_isa($var2, $var1)

However, the sentence: "The captial of Germany is Berlin.", when parsed,
has the subject and object in reverse order, and so, when this rule is
applied, returns a backwards IsA relation ('capital is a berlin'). The
preposition "of" signals the subect-object inversion; but also, the 
determiners clash for an is-a ('the capital is the berlin') -- we expect
the sentence patterns "x is a y" or "x is the y of ..." but not a naked
"x is the y".

   "Berlin is a city"
      DEFINITE-FLAG(Berlin, T)
      noun_number(Berlin, singular)
      noun_number(city, singular)
      _subj(be, Berlin)
      _obj(be, city)

   "The capital of Germany is Berlin."

      DEFINITE-FLAG(Germany, T)
      noun_number(Germany, singular)
      of(capital, Germany)
      DEFINITE-FLAG(capital, T)
      noun_number(capital, singular)
      DEFINITE-FLAG(Berlin, T)
      noun_number(Berlin, singular)
      _subj(be, capital)
      _obj(be, Berlin)

Ignoring the prepositional parts, we get:

      DEFINITE-FLAG(capital, T)
      noun_number(capital, singular)
      DEFINITE-FLAG(Berlin, T)
      noun_number(Berlin, singular)
      _subj(be, capital)
      _obj(be, Berlin)

This suggests that the correct rule for is-a relations is:

   # IF _subj(be, $var1) ^ _obj(be, $var2) 
       ^ !DEFINITE-FLAG($var2)
       THEN ^3_isa($var2, $var1)

The ! in front of DEFINITE-FLAG means "not" or "invert"; the 
DEFINITE-FLAG must be absent, or, if present, must be false.
Note that all top-level clauses (subj, obj, etc.) must have truth
values set so that they're true. This is because the truth value
is examined to compute the effect of !. The default truth value
in Opencog is (false, unconfident), so it must be over-ridden
to state (true, confident).

Consider now: "Men are mortal."
   _predadj(men, mortal)

which suggests the rule:

 # IF _predadj($var1, $var2) THEN ^3_isa($var2, $var1)

However, prepositions again confound word order:
Input sentence: "The color of the sky is blue."
   of(color, sky)
   _predadj(color, blue)

By ignoring the preposition, the sentence becomes: "color is blue", 
i.e. that 'colors' are a kind-of blue, which is inverted from the 
intended sense. The next-most naive rule is then:

  # IF _predadj($var1, $var2) ^ 
       ! $prep($var1,$var3)
       THEN ^3_isa($var2, $var1)

and also the inverted word-order case:

  # IF _predadj($var1, $var2) ^ 
       $prep($var1,$var3)
       THEN ^3_isa($var1, $var2)

XXX However, this doesn't quite work because  $prep($var2,$var3) is
so broad, that it can match to just about anything, including things
are not DefineLinguisticRelationship nodes. Thus, we need to force
type matching in variables.



Deduction
---------
Suppose we have a set of (consistent) prepositional relationships. What
can we do with them?  For example, can we deduce that a certain verb is
a type of locomotion, based on its use with regard to prepositions?

Hmm. Time to write some rules, and experiment and see what happens.
Not clear how unambiguous the copulas and preps will be.

HOWTO
-----
How to run the current code in example/demo/debug mode:
-- start cog-server
-- run load.sh
-- run load-examples.sh  to load the example sentences.
-- Enter the scheme shell
-- run (cog-ad-hoc "do-implication" frame-rule-0) through
   (cog-ad-hoc "do-implication" frame-rule-12) and observe results.

Next step:
-- Download the MIT ConceptNet corpus.
-- This corpus is in N3 format; strip out sentences by 
   running "conceptnet.pl"
-- Parse the sentences using relex, generate opencog output.
-- Create a presistence repository for accumulating results.
   (at this time, create a new SQL db)
       createdb triples
       cat opencog/persist/atom.sql | psql triples
-- Run cogserver
-- open the database created above
-- run load.sh
-- Enter the scheme shell
-- Load previously parsed sentences.
-- run command (do-triples)

6:38 to load part 1


References:
-----------
[WP-RDF] Resource Description Framework
     http://en.wikipedia.org/wiki/Resource_Description_Framework

