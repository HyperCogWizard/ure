
                   Language Learning
                   -----------------
             Linas Vepstas December 2013

Current project, under construction.

Steps:
1) Install the 'any' language for link-grammar
2) Set up and configure postgres, as described in 
   opencog/persist/sql/README
3) createdb learn-pairs
   cat atom.sql | psql learn-pairs
   Edit and setup ~/.odbc.ini
4) Start the cogserver

5) Copy the RelEx opencog-server.sh shell script to some other name.
   Edit it, and replace the final line with this:
   java $VM_OPTS $RELEX_OPTS $CLASSPATH relex.Server --lang any -n 999 --link --port 4444
   Run the new shell script.

   The above tells relex to use the 'any' language, and return up to 999
   different parses.

6) cat ./link-pipeline.scm |netcat localhost 17001

   Better idea: edit build/lib/opencog.conf and add nlp/learn/link-pipeline.scm
   to the list

7) telnet localhost 17001
   opencog> sql-open learn-pairs linas asdf
   opencog> scm
   guile> (observe-text "this is a test")

   Better yet:
   echo -e "scm\n (observe-text \"this is a another test\")" |nc localhost 17001
   echo -e "scm\n (observe-text \"Bernstein () (1876\")" |nc localhost 17001
   echo -e "scm\n (observe-text \"Lietuvos žydų kilmės žurnalistas\")" |nc localhost 17001

8) psql learn-pairs
   learn-pairs=# SELECT * from atoms;

   The above shows that the database now contains word-counts for
   pair-wise linkages for the above sentences.

9) Get ready to feed it text.  For example, parse wikipedia.
   a) Download lang-wiki-pages-articles for some lanugage lang.
   b) See 'Wikipedia processing' section below. Do the stuff there.
   c) See the section 'Sentence Splitting'. Set that up.
   d) See Wikipedia 'Processing, part II' below.

10) Do the stuff in section "Mutual Information".

That's all for now, folks!


TODO
----
* Remove the NLP_HACK from persist/sql/PersistModule.cc
* Optimize the scm scripts to not pound the database so hard.
  (How? Lots of word pushes, but really, there's not much repeat
  traffic ...)
* Investigate crash: while writing truuth value, stv_confidence 
  was pure virtual (circa line 920 of AtomStorage.cc)
  -- this only happened when I allowed the atomspace to get
     bigger, by not agressively deleting old sentences!
     I don't see what this has to do with it ...

DONE
----
* Make sure that link-parser fully randomizes linkage choices for
  long sentences. Done. See the rand_state and predictable_rand
  flags in version 4.8.3.
* Need a mutli-language sentence splitter; the maxent splitter only
  works for English sentences.  Probably something simple will do ...
  Done: copied one from moses-smt and put it into a relex subdirectory
* Raw psql seems not to be utf8.  Were the tables created wrong,
  or is this a client bug? 
  Fixed: turned out to be a guile-related bug.
* Handle database write asynchronously: have a thread collect
  up the atoms, and write them. Maybe even multiple threads.
  This is OK due to the atomptr design.
  Done.  Not just one, but multiple writers.
* Can we start a guile thread for each incoming sentence?
  Threading will require more subtle sentence cleanup.
  No. The main guile bug, opened 5 years ago, is still not fixed.
* Table counts need to be more than 32-bit. Looks like the 
  any-language goes hog-wild and creates huge counts for just
  one sentence ... is this desired?  Anyway, they'll overflow...
  Done. atoms.sql now uses bigint 64-bit uuids.


Notes:
------
The relex parse is extreely fast, the cogserver part is extremely slow ... 
Non-linear, even.
4-word sentence: 53 parses, 3-4 seconds elapsed

5-word sentence, 373 parses,
32 second elapsed,
postgres runs at 36% cpu
cogserver runs at 56% cpu for a while then drops to 26% cpu

8-word sentence, max of 999 parses,
2 minutes elapsed.  Same CPU usage as above...


Wikipedia processing
--------------------
Do the following:
    createdb fr_pairs lt_pairs pl_pairs simple_pairs
    cat opencog/persist/sql/atom.sql | psql
    vi .odbc.ini  learn-fr learn-lt learn-pl learn-simple

cleanup files in relex: src/perl

    cd /storage/wikipedia

    mkdir wiki-stripped
    time cat blahwiki.xml.bz2 |bunzip2 | /home/linas/src/relex/src/perl/wiki-scrub.pl
    cd wiki-stripped
    find |wc
    /home/linas/src/relex/src/perl/wiki-clean.sh
    find |wc
    cd ..
    mkdir alpha-pages
    cd alpha-pages
    /home/linas/src/relex/src/perl/wiki-alpha.sh

simple:
find |wc     gives 131434 total files
find |wc     gives 98825 files after cat/template removal.

lt:
7 mins to unpack
find |wc gives 190364 total files
find |wc gives 161463 after cat/template removal

pl:
1 hour to unpack (15 minutes each part)
find | wc gives 1097612 articles
52K are categories
35K are templates
find |wc gives 1007670 files after cat/template removal

fr:
3 hours to unpack (25-60 minutes per glob)
find |wc gives 1764813 articles
214K are categories
55K are templates
find |wc gives 1452739 files after cat/template removal


Sentence Splitting
------------------
Needs to be multi-language
Maybe NLTK ? .. Not today, but you can experiment.
Long-term goal is to have opencog know how to sentence-split itself,
but this is secondary prioruity.

Here's a simple one, easy-to-use:
https://github.com/moses-smt/mosesdecoder/tree/master/scripts/share/nonbreaking_prefixes
Has french, polish, latvian
its LGPL
Copy this over into relex, for now. (Its in the RelEx sources)

cat /storage/wikipedia/ltwiki-20131216-pages-articles/alpha-pages/A/./Akiduobė | /home/linas/src/relex/src/split-sentences/split-sentences.pl -l lt > x

A question mark or exclamation mark always ends a sentence.  A period followed by an
upper-case letter generally ends a sentence, but there are a number of exceptions.  For
example, if the period is part of an abbreviated title ("Mr.", "Gen.", ...), it does not end a
sentence.  A period following a single capitalized letter is assumed to be a person's initial,
and is not considered the end of a sentence.

(setlocale LC_ALL "")
 (display "Ćićolina")


Wikipedia Parsing, part II
--------------------------
Now, build some working directories (so that we don't mess up
alpha-pages after all that work)

    cp -pr alpha-pages beta-pages

* Copy scripts from opencog/nlp/learn/misc-scripts into working dir.
* Modify as needed for chosen language. 
* Make sure the scripts point at the RelEx parse server.
* Copy opencog-lang.conf to opencog build dir.
  Start cogserver -c opencog-lang.conf 
* Go back to the wikipedia dir, and run ./wiki-ss-lang.sh
* Wait a few days.
* Be sure to psql lang_pairs -c "VACUUM ANALYZE;" every 4 hours or so,
  as otherwise, performance craters.  Be sure to perform the postgres
  tuning recommendations fount in postgress peformance wiis, or in
  the opencog/persist/sql/README file.  See also 'Performance' section
  below.

Some handy SQL commands:
SELECT count(uuid) FROM Atoms;
select count(uuid) from  atoms where type = 77;

type 77 is WordNode for me; verify with
SELECT * FROM Typecodes;


Mutual Information
------------------
Compute mutual information, manually, by runnning these scripts:
compute-mi.scm


Crash
-----
pure virtual method called
terminate called without an active exception
[2013-12-27 03:13:59:571] [ERROR] Caught signal 6 (Aborted) on thread

        11: AtomStorage.cc:920
opencog::AtomStorage::do_store_single_atom(std::shared_ptr<opencog::Atom>, int)
STMTF("stv_confidence", tv->getConfidence());

Again: 
        9: ??:0 __cxa_pure_virtual()
        10: AtomStorage.cc:929    opencog::AtomStorage::do_store_single_atom(std
::shared_ptr<opencog::Atom>, int)
        11: AtomStorage.cc:802
opencog::AtomStorage::do_store_atom(std::shared_ptr<opencog::Atom>)

this time, line 929 is:
926        // Store the truth value
927        TruthValuePtr tv = atom->getTruthValue();
928        TruthValueType tvt = NULL_TRUTH_VALUE;
929        if (tv) tvt = tv->getType();

again... 26 December, no stack-trace, but got "called pure virtual" error msg.
again... 27 December line 939: STMTF("stv_confidence", tv->getConfidence());
again... 27 Dec, 929        if (tv) tvt = tv->getType();
again... 28 Dec, didn't get a stack...

All new crash. Note:
1) This is with the old scheme singleton-instance.
2) This one received when defining a function with an unbound variable
   in it.  It should have just been a standard stack trace, but wasn't.
3) Sometimes, when doing this, and parser is running, I get 

[2013-12-26 22:50:57:680] [ERROR] Caught signal 11 (Segmentation fault) on threa
d 47486186035520
        Stack Trace:
        2: CogServerMain.cc:92  _Z7sighandi()
        3: sigaction.c:0        __restore_rt()
        4: ??:0   std::string::append(std::string const&)
        5: basic_string.h:290     std::string::_M_data() const
        6: SchemeEval.cc:381      opencog::SchemeEval::c_wrap_eval(void*)
line 381 is  self->answer = self->do_eval(*(self->pexpr));
So maybe p is null, or self->pexpr is null..
        7: continuations.c:511  c_body()
        8: vm-i-system.c:855    vm_regular_engine()
        9: eval.c:508   scm_call_4()
        10: continuations.c:456 scm_i_with_continuation_barrier()
        11: continuations.c:550 scm_c_with_continuation_barrier()
        12: pthread_support.c:1272      GC_call_with_gc_active()
        13: threads.c:937       with_guile_and_parent()
        14: misc.c:1835 GC_call_with_stack_base()
        15: threads.c:959       scm_with_guile()
        16: SchemeEval.cc:372     opencog::SchemeEval::eval(std::string const&)
        17: basic_string.h:536  ~basic_string()
        18: GenericShell.cc:157   opencog::GenericShell::eval(std::string const&, opencog::ConsoleSocket*)
        19: ConsoleSocket.cc:232          opencog::ConsoleSocket::OnLine(std::string const&)
        20: basic_string.h:536  ~basic_string()
        21: thread.cpp:0        thread_proxy()
        22: pthread_create.c:0  start_thread()
        23: ??:0        __clone()




Performance
-----------
Performance seems to suck: 
-- two parsers, each takes maybe 4% cpu time total. Load avg of about 0.03
-- each parser runs 4 async write threads pushing atoms to postgres. 
   each one complains about it taking too long to flush the write queues.
-- postmaster is running 10 threads, load-avg of about 2.00  so about
   2 cpu's at 100%
-- vmstat shows 500 blks per second written. This is low...
-- top shows maybe 0.2% wait state. So its not disk-bound.
-- what is taking so long?

So, take a tcpdump:
-- a typical tcpdump packet:
   UPDATE Atoms SET tv_type = 2, stv_mean = 0 , stv_confidence = 0, stv_count = 54036 WHERE uuid = 367785;
   its maybe 226 bytes long.
-- this gets one response from server, about 96 bytes long.
-- then one more req, one more repsonse, seems to be a 'were'done' mesg
   or something ...  which I guess is due to SQLFreeHandle(SQL_HANDLE_STMT ???
-- time delta in seconds, of tcpdump of traffic packets, between update, and 
   response from server:
   0.0006  0.0002 0.0002 0.0002 0.028 (yow!!) 0.001 0.0002

-- so it looks like about every 8-10 packets are replied to failry quick,
   then there's one that takes 0.025 seconds to reply.... stairsteps in
   response time like this all the way through the capture.

Wild guess:
-- Hmm ... this seems to be related to the commit delay in postgresql.conf
   Change commit_delay to 1 second
   change wal_bufers to 32MB since its mostly update traffic.
   change checkpoint_segments to 32 (each one takes up 16MB of disk space.)

-- Making these changes has no obvious effect ... bummer.

I don't get it; performance sucks and I don't see why.  Or rather: postmaster
is chewing up vast amounts of cpu time for no apparent reason...


select * from pg_stat_user_tables;
select * from pg_stat_all_tables;
select * from pg_statio_user_tables;
select * from pg_database;

pg_stat_user_indexes
pg_stat_all_indexes

select * from pg_catalog.pg_stat_activity;
select * from pg_catalog.pg_locks;


-- WOW!!!   VACUUM ANALYZE; had a huge effect!!

-- vacuum tells em to do following:
   change max_fsm_pages to 600K
   chage max_fsm_relations to 10K

Anyway ... performance measured as of 27 Dec 2013:

Takes about 105 millisecs to clear 90 eval-links from the write-back
queues. This each eval-link is 5 atoms (eval, defind, list, word, word)
so this works out to 5*90 atoms /0.105 seconds = 4.3KAtoms/sec 
which is still pretty pathetic... 

Misc 
----

Loaded 10000 atoms.  Oh, OK.

Change load-atoms to return a count?

handle SIGPWR nostop noprint
handle SIGXCPU nostop noprint


