                          Question Answering
                          ------------------
               Linas Vepstas <linasvepstas@gmail.com>
                        Created 18 March 2008
                        Revised on 13 May 2008

This directory contains code that implements natural language question
answering via subgraph isomorphism. This README file describes the 
operation and reports on experimental results. The experiments examined
a fairly simple question-answering technique, which, although functional,
is not very robust. The basic idea is that NL parses of assertions, such
as "John threw the ball", and questions, such as "Who threw the ball?"
resemble each other quite closely. One need only recognize "who" as an
implicit variable name, and then search over the entire atomspace to 
find a matching pattern, at which point the word "John" can be used 
as a grounding for the variable "who?".

Two sets of experiments are reported: pattern matching at the RelEx
level, and pattern matching at the Frame level. The RelEx level 
represents sentences as collections of subject, object relations, 
together with noun number, verb tense, etc. markup.  The Frame 
level decorates the basic RelEx relations with situational context
infered from the sentences.

XXX As of 13 May 2008, changes to the RelEx output have broken the 
operation of this code. Basically, the output generated by RelEx
no longer matches up with what this code is expecting. Thus, it no 
longer functions. Some steps have been taken to bring this into line.

General conclusion: while question answering is possible, it could be
made much more robust by implementing two ideas. One idea is to identify
synonymous phrases, as described by Lin & Patel [Lin2001]. The other
is to create more compact representations of concepts, along the lines
of work described in nlp/triples/README.  Thus, work on question
answering is suspended until the above objectives are reached.

* [Lin2001] Dekang Lin and Patrick Pantel. 2001.  "Discovery of Inference
  Rules for Question Answering." ''Natural Language Engineering'' 
  '''7'''(4):343-360.  http://www.cs.ualberta.ca/~lindek/papers/jnle01.pdf 

Question Answering Overview
---------------------------
Query processing proceeds by taking English language sentences, 
passing them through the link-grammar parser, then through RelEx,
through the semantic framing, and then importing the result into
OpenCog.

When a sentence is determined to be a query, the above-described
pattern matching is performed on the contents of OpenCog, in an
attempt to find a matching result.  Pattern matching can be done
at several levels: at the RelEx level, or at the more abstract
semantic framing level.  Query processing at the RelEx level should
be used only when a very narrow, literal answer is desired. This
is because pattern matching at the RelEx level introduces very
little wiggle room.  Thus, for example, to answer the question
"What did John throw?" at the RelEx level,

    _subj(throw, John )
    _obj(throw, _$qVar)

The OpenCog server must contain a sentence that had parsed into
exactly the above form; so, for example: "John threw a ball"

    _subj(throw, John )
    _obj(throw, ball)

would provide a matching solution, whereas ...

(provide example)

Thus, a looser matching, based on deeper semantic understanding,
is desirable.  This is afforded by using the semantic framing 
matcher.


RelEx pattern matching
----------------------
A detailed example of RelEx relationship matching follows.

"John threw a ball."

_subj(throw, John)
_obj(throw, ball)
tense(throw, past)
noun_number(ball, singular)
DEFINITE-FLAG(John, T)
noun_number(John, singular)

"What did John throw?"

_subj(throw, John)
_obj(throw, _$qVar)
tense(throw, past_infinitive)
HYP(throw, T)
QUERY-TYPE(_$qVar, what)
DEFINITE-FLAG(John, T)
noun_number(John, singular)

Eliminate the HYP and QUERY-TYPE from the question, since
the answer will never contain these. One is left with:

_subj(throw, John)
_obj(throw, _$qVar)
tense(throw, past_infinitive)
DEFINITE-FLAG(John, T)
noun_number(John, singular)

Clearly, the RelEx pattern of the question can be matched to 
the RelEx pattern of the answer, to find that _$qVar == ball.
(Some twiddling required to match tense correctly).
This type of RelEx relation-level setup, query massaging 
and node matching is implemented in RelexQuery.cc, RelexQuery.h
It seems to work, but hasn't undergone strenuous testing.

Pattern matching at the RelEx level is not always possible, as shown
next. At the root of the problem is that RelEx provides only a small
amount of "semantic normalization". That is, RelEx will abstract 
(pull out, normalize) some, but not much, semantics.  Similar 
statements will be similar, whereas the query processor is looking for
exact matches, and not merely similarities.  Thus, query processing
will fail without exact matches. A mechanism will be needed for handling
"similar" statements with similar meanings.


Copula troubles:
----------------
Intensional/extensional inheritance causes problems for 
simple RelEx matching.

Yarn is a length of fibers.
_subj(be, yarn)
_obj(be, length)
tense(be, present)
of(length, fiber)
noun_number(length, singular)
noun_number(fiber, plural)
noun_number(yarn, uncountable)


Yarn is what?
(fails to parse in link-grammar)

What is yarn?

_subj(be, _$qVar)
_obj(be, yarn)
tense(be, present)
noun_number(yarn, uncountable)
COPULA-QUESTION-FLAG(yarn, T)
QUERY-TYPE(_$qVar, what)
noun_number(_$qVar, uncountable)

Note that the _subj and _obj are exchanged in the query, 
preventing a direct match.


Frame matching
--------------
The goal of working with frames rather than RelEx relations is
to escape from the strictures of the syntactic relations, and
move to a more semantic interpretation.

Yarn is a length of fibers.

^1_Categorization:Category(be,length)
^1_Existance:Entity(be,yarn)
^2_Inheritence:Quality(of,length)
^2_Inheritence:Inheritor(of,fiber)
^2_Inheritence:Group(of,fiber)
^2_Inheritence:Instance(of,length)
^1_Partitive:Subset(of,length)
^1_Partitive:Group(of,fiber)
^1_Part_whole:Part(of,length)
^1_Part_whole:Whole(of,fiber)
^1_Physical_entity:Constituents(of,fiber)
^1_Physical_entity:Entity(of,length)
^1_Categorization:Item(be,yarn)
^1_Temporal_colocation:Time(present,be)
^1_Temporal_colocation:Event(present,be)


What is yarn?

^1_Existance:Entity(be,_$qVar)
^1_Categorization:Category(be,yarn)
^1_Temporal_colocation:Time(present,be)
^1_Temporal_colocation:Event(present,be)
^1_Categorization:Item(be,_$qVar)
^1_Entity:Entity(what,_$qVar)
^1_Questioning:Message(what,_$qVar)
^1_Attributes:Entity(what,_$qVar)

Trim the question to remove references to questioning (as the answer
won't possess these). Remove the "what" part as well. The question
becomes:

^1_Categorization:Category(be,yarn)
^1_Temporal_colocation:Time(present,be)
^1_Temporal_colocation:Event(present,be)
^1_Categorization:Item(be,_$qVar)
^1_Existance:Entity(be,_$qVar)

The goal of pattern matching is to glue (i.e. pattern-match) 
the above five clauses onto the original assertion that 
"yarn is a length of fibers".

The glueing fails. I want to get the answer that $qVar == length.
But I cannot match up ^1_Existance:Entity(be,_$qVar)
to ^1_Existance:Entity(be,length) --

Next, I want to match up ^1_Categorization:Category(be,yarn),
(from the question) to ^1_Categorization:Item(be,yarn) (from
the answer) but I can't. 

This asymmetry of the question and its answer has me blocked.

The root problem seems to be that both

_subj(be, _$qVar)
_obj(be, yarn)
and
_obj(be, _$qVar)
_subj(be, yarn)

are valid forms for the question. The second one should be
more common, but its not the one being generated. There 
should probably be a frame rule to reverse this order.

============
Step back; look at frame matching in a simpler example.

John threw a ball. 
^1_Body_movement:Agent(throw,John)
^1_Cause_motion:Theme(throw,ball)
^1_Transitive_action:Agent(throw,John)
^1_Temporal_colocation:Event(past,throw)
^1_Temporal_colocation:Time(past,throw)
^1_Body_movement:Body_part(throw,ball)
^1_Cause_motion:Cause(throw,John)
^1_Transitive_action:Object(throw,ball)


What did John throw?

^1_Body_movement:Agent(throw,John)
^1_Cause_motion:Theme(throw,_$qVar)
^1_Transitive_action:Agent(throw,John)
^1_Entity:Entity(what,_$qVar)
^1_Questioning:Message(what,_$qVar)
^1_Attributes:Entity(what,_$qVar)
^1_Possibilites:Event(hyp,throw)
^1_Body_movement:Body_part(throw,_$qVar)
^1_Cause_motion:Cause(throw,John)
^1_Transitive_action:Object(throw,_$qVar)


Remove "Questioning" and "what".

^1_Body_movement:Agent(throw,John)          -- OK match
^1_Cause_motion:Theme(throw,_$qVar)         -- OK _$qVar == ball.
^1_Transitive_action:Agent(throw,John)      -- OK match
^1_Body_movement:Body_part(throw,_$qVar)    -- OK _$qVar == ball
^1_Cause_motion:Cause(throw,John)           -- OK match
^1_Transitive_action:Object(throw,_$qVar)   -- OK _$qVar == bal

This type of RelEx frame-level setup, query massaging 
and node matching is implemented in FrameQuery.cc, FrameQuery.h
It seems to work, but hasn't undergone strenuous testing.

Testing
-------
Some test corpus material, and test results:

====
Mike threw a rock.
John threw a ball and a screwdriver.
John ate a peach.
What did John throw?

RelEx matching provides two correct answers: 
_$qVar = ball, and _$qVar = screwdriver.
====

The book is red. What color is the book?
The color of the book is red. What color is the book?

Both of these fail on the simple pattern match.

====
Yarn is a length of fibers.
What is yarn?

Fails, as discussed above
====
Yarn is used to make cloth.
What is yarn used for?

_to-do(use, make)
_obj(use, yarn)
tense(use, present)
_subj(make, yarn)
_obj(make, cloth)
tense(make, infinitive)
HYP(make, T)
noun_number(cloth, uncountable)
noun_number(yarn, uncountable)

The assertion has a second parse, with "to" instead of "_to-do"

The question has three parses. The first is:

for(use, for)
_obj(use, yarn)
tense(use, present)
_amod(for, use)
_obj(for, _$qVar)
tense(for, present)
noun_number(yarn, uncountable)

All three parses contain _obj(use, yarn), and that's good.

Clearly, the pattern match here fails. All three parses contain
_obj(for, _$qVar) which cannot be matched to the original assertion.

All three contain either _amod(for, use) or _amod(for, be)
and these _amod's cannot be matched to the original assertion.

The frame situation is no better.  The assertion frame is:

^1_Transitive_action:Agent(make,yarn)
^1_Ingest_substance:Substance(use,yarn)
^1_Intentionally_create:Creator(make,yarn)
^1_Using:Instrument(use,yarn)
^1_Building:Created_entity(make,cloth)
^1_Causation:Affected(make,yarn)
^1_Arriving:Theme(make,yarn)
^1_Causation:Effect(make,cloth)
^1_Ingest_substance:Purpose(use,make)
^1_Cause_change:Cause(make,yarn)
^1_Possibilites:Event(hyp,make)
^1_Using:Purpose(use,make)
^1_Arriving:Goal(make,cloth)
^1_Temporal_colocation:Time(present,use)
^1_Temporal_colocation:Event(present,use)
^1_Transitive_action:Cause(verb,use)
^1_Transitive_action:Event(verb,make)
^1_Cooking_creation:Cook(make,yarn)
^1_Building:Agent(make,yarn)
^1_Cooking_creation:Produced_food(make,cloth)
^1_Intentionally_create:(make,cloth)
^1_Transitive_action:Object(make,cloth)
^1_Transitive_action:Object(use,yarn)
^1_Manufacturing:Product(make,cloth)
^1_Manufacturing:Factory(make,yarn)
^1_Cause_change:Entity(make,cloth)

The appearance of "cooking" is unexpected.  "Building" is odd 
Why not "manufacture" or "intentionally_create"?

"Ingest" is ... and odd way of saying that the yarn is used up...

  "What is yarn used for?"

Has the frameset below.  I've manually removed Questioning:Message, 
etc. as these are explicitly ignored for the question pattern match.
I've marked up each according to whether the frames echoed the
assertion:


^1_Using:Purpose(use,for)                         -- no match
^1_Ingest_substance:Substance(use,yarn)           == OK
^1_Using:Instrument(use,yarn)                     == OK
^1_Relative_time:Focal_occasion(for,for)          -- no match
^1_Relative_time:Landmark_occasion(for,use)       -- no match
^1_Temporal_colocation:Time(present,use)          == OK
^1_Temporal_colocation:Event(present,use)         == OK
^1_Temporal_colocation:Event(present_1,for)       -- no match
^1_Temporal_colocation:Time(present_1,for)        -- no match
^1_Ingest_substance:Purpose(use,for)              -- no match
^1_Transitive_action:Object(for,_$qVar)           -- no match
^1_Transitive_action:Object(use,yarn)             == OK

The word "for" seems to lie at the root of the problem.  
Lets try a different assertion:

  "Yarn is used for making cloth."

A clause by clause comparison shows that this doesn't match
the question any better then before. So pattern matching the
question fails here too.  

How similar are the two assertions? Lets compare RelEx output first;
ignoring tense, noun_number, which are correct, we have:

  "Yarn is used for making cloth."
_obj(use, yarn)
_amod(for, use)
_subj(make, for)
_obj(make, cloth)

  "Yarn is used to make cloth."
_to-do(use, make)
_obj(use, yarn)
_subj(make, yarn)
_obj(make, cloth)
HYP(make, T)

The only agreement is that both correctly state _obj(make, cloth)
and _obj(use, yarn)  However, _subj in both is confusing, and 
it seems hard to induce that the thing being used is also the 
input to the thing being made.

  "Yarn is used in making cloth."

_obj(use, yarn)
_amod(in, use)
_subj(make, in)
_obj(make, cloth)

  "Yarn is used in the making of cloth."

in(use, making)
_obj(use, yarn)
of(making, cloth)

The frame rules do not seem to introduce more commonality
between these; rather, they seem to diverge even more. Thus,
instead of the frames making things seem "more semantically
similar", they seem to do the opposite.

Now, some sort of fuzzy matching could be done here, since there
is clearly some non-zero overlap between all of these. Even more
so: it seems like the common parts of all of these ways of saying 
this capture the "underlying truth" the best. But without a large 
corpus, without lots of activation, and repeated similar but not 
identical restatements of the same ideas, I don't see any particularly
good ways of inducing that yarn is used to make cloth...


See:
http://www.cs.ualberta.ca/~lindek/papers.htm
Dekang Lin and Patrick Pantel. 2001. Discovery of Inference Rules for
Question Answering. Natural Language Engineering 7(4):343-360. [PDF][PS]

See also:
DIRT - Discovery of Inference Rules from Text, Dekang Lin and Patrick Pantel.


Query processing architectural issues:
--------------------------------------
Below are some architectural issues that have been given temporary
solutions, but need a better long-term solution.

-- How to distinguish rhetorical questions from queries that should
   be answered?  A block of input text may contain rhetorical questions,
   which should be ignored.

-- How should query processing be triggered?  What channel should be
   used for reply? Currently, all input to CogServer is via XML, which
   is parsed. If the parse is successful, no further processing is done.

   Query processing could be performed by a mind agent, but how should
   its activity be triggered, and what communications channel should
   it use to post a reply?


Diary and Notes
---------------
Use special token to trigger mind agent. Per Ben, "DialogManager",
there are four such tokens:
-- query
-- statement
-- command
-- interjection



