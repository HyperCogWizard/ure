
                    Natural Language Processing
                    ---------------------------
                     Linas Vepstas April 2008

This directory contains a miscellany of natural language processing
tools (for the English language). Current focus is on establishing
statistical correlations between word senses and gramatical constructions,
on reference resolution, and on reasoning with prepositional relations.

How-To
======
The current code "doesn't do anything yet"; rather, it is a platform for
running experiments. Thus, what is contained here should be thought of
as a "bag of parts".  It is up to you to figure out what these parts
are, and to assemble them into something meaningful.

Currently, there are three basic experimental flows that are possble:
the semantic triples process, the word-sense-disambiguation (WSD) process, 
and the question-answering process.  The semantic-triples process is
described in nlp/triples/README, and is the simplest/most-straightforward
experiment. The question-answering process is described in 
nlp/question/README, and is also very striaght-forward. The most
difficult process is WSD, which requires creating and maintain large,
complex databases.  It is summarized here:

 * Download and compile opencog, relex, lexical-attraction from
   launchpad.
 * Create a bunch of SQL tables, as specified in the lexical-attr 
   package. Configure locations and passwords in opencog.conf.
 * Parse a bunch of English text, using relex, to obtain frequency
   counts. Alternately, download pre-parsed texts from 
   http://relex.swlabs.org/~linas/ which contains several cpu-years
   worth of parsed data. 
 * Run the scripts in the wordnet-import directory to load opencog
   with basic wordnet relationships.
 * Modify A.scm to change the hard-coded paths to point at the actual
   location of the data.
 * Run "nlp/scm/load-nlp.sh" to load NLP and WSD-related scheme utilities. 
 * Get to the scheme prompt, and run "(do-wsd 20)". This will run the
   current word-sense disambiguation code one 20 files, and will populate
   the databases with statistical results.  Caution; this is extremely 
   CPU-intensive.
 * Read the README in wsd-post and triples for latest info & results.

The lexical attraction package, at https://launchpad.net/relex-statistical
is used to define SQL tables holding assorted relationships, including
tables of mutual information between word pairs, and tables of conditional
probabilities of link-grammar disjuncts. These tables are referenced 
and/or generated by some of the opencog code here. 

Database dumps of some of the statistical datasets can be downloaded from
http://relex.swlabs.org/~linas/  These represent several CPU-years of 
number-crunching, and so are a short-cut to getting results more quickly.


Subdirectories (in alphabetical order)
======================================
chatbot
-------
The chatbot directory contains some crude code to tie opencog NLP
processing to chat systems, and particularly, to IRC chat. 

lexical_attraction
------------------
The lexical-attraction directory contains a REAME file containing a
short overview of Yuret's lexical attraction algorithm. A variant of
this algo was implemented in java, in the lexat project on launchpad.

question
--------
C++ code that implements a basic question-answering algorithm, based on
matching the NL pattern of a question to the NL pattern of an assertion.
If the atomspace contains an assertion such as "John threw the ball", 
then this code can correctly answer the question "Who threw the ball?"

refres
------
Some working notes on reference resolution.
The core problem of reference resolution is determining when two words
in a text refer to the same concept. Thus, for example, the same noun,
used in neighboring sentences, probably refers to the same concept.
Alternately, anaphora (he, she, it, etc.) may also be used to refer to
the same concept.

scm
---
The scm directory contains some scheme scripts. This includes scripts
for pulling out link-grammar disjuncts from parse data, and
storing/updating disjunct frequency counts in an SQL database. These
frequency counts are tied to word senses, obtained via the Mihalcea
word-sense disambiguation algo.

semcor
------
The semcor directory contains some trite SemCor utilities. SemCor
is a WSJ corpus marked up with word senses.  This directory is nearly
empty and is not currently used.

similarity
----------
The similarity directory contains code related to similarity of word
senses.  Describes plans/code for storing wordnet-derived similarity
measures within OpenCog.

triples
-------
The triples directory contains some experimental code for extracting
prepositional triples from text. So, for example: "Lisbon is the 
capital of Portugaul" would be turned into "capital_of(Portugaul,
Lisbon)".  Such "prepositional relations" extend the usual ontological 
concepts of "is_a", "has_a", "part_of" and "uses" to more general
relations.

The directory contains a script to convert RelEx Frame rules into 
opencog ImplicationLinks.

types
-----
Scripts, etc. to load NLP-specific atom types.

wordnet-import
--------------
The wordnet-import directory contains stand-alone code (i.e. not a part
of opencog) that will walk over the wordnet database, and convert it 
into OpenCog Scheme, which can then be easily loaded into OpenCog.

wsd
---
The wsd directory contains code that implements the Rada Mihalcea 
word-sense disambiguation algorithm.  The Mihalcea algorithm assigns
senses to the words in a sentence, and constructs links between these
different senses. The links are weighted by a word-sense similarity
measure. The result is a graph whose vertices are word-senses, and 
whose edges are these links.  The graph is essentially just a Markov 
chain, and is solved as such, looking for a stationary vector of 
probabilities for the word-sense verticies. The verticies with the 
highest scores are then the most likely meaning for a word.

wsd-post
--------
The wsd-post directory contains miscellaneous post-processing and data
analysis scripts for analyzing the results of WSD processing.  These 
results are stored in various SQL tables, and contain wordnet and 
link-grammar disjunct statistics. The wsd-post directory contains
scripts to compute conditional probabilities, etc.  See the README
there for research notes providing more info.

======================================================================

Input file format
-----------------
This style of input may be produced in one of two ways. It is produced
directly by RelEx, when using the opencog output format: the -o flag
appended to the relex.RelationExtractor executable. The other way is
indirect, but can be considerably more convenient: First, parse text
using the  relex.WebFormat module, to create the "compact file format".
Then, use the relex/src/perl/cff-to-opencog.pl perl script to convert 
this to the final output. 


A Side-note About Syntactic Sugar
===================================
This has been said before, but it bears repeating. Consider the node
type WordInstanceNode, for example:

    (WordInstanceNode "cabin@99d22336-6cda-4365-8555-64260ed8bd15")

This custom-defined node type should be thought of as syntactic sugar
for the more "primitive" graph:

   (InheritenceLink
        (ConceptNode "cabin@99d22336-6cda-4365-8555-64260ed8bd15")
        (ConceptNode "WordInstance")
    )

The above InheritenceLink essentially assigns a "type" to the word
instance. This type can be used in the same way that types are
ordinarily used in other programming langauges. When managing
hypergraphs, it is almost always easier and faster to locate,
manipulate and delete narrowly typed atoms.

Similarly, for links, we use the syntactic sugar

    (PartOfSpeechLink
        (WordInstanceNode "cabin@99d22336-6cda-4365-8555-64260ed8bd15")
        (DefinedLinguisticConceptNode "noun")
    )

which stands for the more "primitive" construct:

    (EvaluationLink
        (PredicateNode "PartOfSpeech"
            (ListLink
                (WordInstanceNode "cabin@99d22336-6cda-4365-8555-64260ed8bd15")
                (DefinedLinguisticConceptNode "noun")
            )
        )
    )

Notationally, these forms should be considered to be "equivalent"
although there is a bunch of actual code that depends on the one or
the other, cand cannot freely intermingle these cases.

Not everything in the RelEx export gets its own specially-declared
node or link type. Those that do not are explicitly declared in the
file "src/nlp/scm/type-definitions.scm"

======================================================================
References:
-----------
"To verbize one's nouns" -- the concept of "Lexical Implication Rules": 
N. Ostler, B.T.S.Atkins, "Predictable Meaning Shift: Some Linguistic
Properties of Lexical Implication Rules", (1991) Proceedings of the
First SIGLEX Workshop on Lexical Semantics and Knowledge Representation

