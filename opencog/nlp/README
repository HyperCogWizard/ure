
                    Natural Language Processing
                    ---------------------------
                     Linas Vepstas April 2008

This directory contains a miscellany of natural language processing
tools (for the English language). Current focus is on word sense
disambiguation and reference resolution.

How-To
======
The current code "doesn't do anything yet"; rather, it is a platform for
running experiments. Thus, what is contained here should be thought of
as a "bag of parts".  It is up to you to figure out what these parts
are, and to assemble them into something meaningful.

Currently, the basic experimental flow is as follows:
 * Download and compile opencog, relex, lexical-attraction from
   launchpad.
 * Create a bunch of SQL tables, as specified in the lexical-attr 
   package.
 * Parse a bunch of English text, using relex, to obtain frequency
   counts.
 * Run the scripts in the wordnet-import directory to load opencog
   with basic wordnet relationships.
 * Run "src/scm/load.sh" and "src/nlp/scm/load-nlp.sh" to load basic
   scheme utilities.
 * Get to the scheme prompt, and run "(doit)". This will run the
   current word-sense disambiguation code, and will populate the 
   databases with statistical results.  Caution; this is extremely 
   CPU-intensive.


Subdirectories (in alphabetical order)
======================================
lexical_attraction
------------------
The lexical-attraction directory contains a REAME file containing a
short overview of Yuret's lexical attraction algorithm. A variant of
this algo was implemented in java, in the lextat project on launchpad.

refres
------
Some working notes on reference resolution.
The core problem of reference resolution is determining when two words
in a text refer to the same concept. Thus, for example, the same noun,
used in neighboring sentences, probably refers to the same concept.
Alternately, anaphora (he, she, it, etc.) may also be used to refer to
the same concept.

scm
---
The scm directory contains some scheme scripts. This includes scripts
for pulling out link-grammar disjuncts from parse data, and
storing/updating disjunct frequency counts in an SQL database. These
frequency counts are tied to word senses, obtained via the Mihalcea
word-sense disambiguation algo.

semcor
------
The semcor directory contains some trite SemCor utilities. SemCor
is a WSJ corpus marked up with word senses.  This directory is nearly
empty and is not currently used.

similarity
----------
The similarity directory contains code related to similarity of word
senses.  Describes plans/code for storing wordnet-derived similarity
measures within OpenCog.

wordnet-import
--------------
The wordnet-import directory contains stand-alone code (i.e. not a part
of opencog) that will walk over the wordnet database, and convert it 
into OpenCog Scheme, which can then be easily loaded into OpenCog.

wsd
---
The wsd directory contains code that implements the Rada Mihalcea 
word-sense disambiguation algorithm.  The Mihalcea algorithm assigns
senses to the words in a sentence, and constructs links between these
different senses. The links are weighted by a word-sense similarity
measure. The result is a graph whose vertices are word-senses, and 
whose edges are these links.  The graph is essentially just a Markov 
chain, and is solved as such, looking for a stationary vector of 
probabilities for the word-sense verticies. The verticies with the 
highest scores are then the most likely meaning for a word.

======================================================================

Input file format
-----------------
This style of input may be produced in one of two ways. It is produced
directly by RelEx, when using the opencog output format: the -o flag
appeneded to the relex.RelationExtractor executable. The other way is
indirect, but can be considerably more convenient: First, parse text
using the  relex.WebFormat module, to create the "compact file format".
Then, use the relex/src/perl/cff-to-opencog.pl perl script to convert 
this to the final output. 


A Side-note About Syntatactic Sugar
===================================
This has been said before, but it bears repeating. Consider the node
type WordInstanceNode, for example:

   (WordInstanceNode "cabin@99d22336-6cda-4365-8555-64260ed8bd15")

This custom-defined node type should be thought of as syntatctic sugar
for the more "primitive" graph:

   (InheritenceLink
		(ConceptNode "cabin@99d22336-6cda-4365-8555-64260ed8bd15")
		(ConceptNode "WordInstance")
	)

The above InheritenceLink essentially assigns a "type" to the word
instance. This type can be used in the same way that types are
ordinarily used in other programming langauges.

Similarly, for links, we use the syntactic sugar

	(PartOfSpeechLink
	   (ConceptNode "cabin@99d22336-6cda-4365-8555-64260ed8bd15")
	   (DefinedLinguisticConceptNode "noun")
	)

which stands for the more "primitive" construct:

	(EvaluationLink
		(PredicateNode "PartOfSpeech"
		(ListLink
			(ConceptNode "cabin@99d22336-6cda-4365-8555-64260ed8bd15")
			(DefinedLinguisticConceptNode "noun")
		)
	)

Notationally, these forms should be considered to be "equivalent"
although there is a bunch of actual code that depends on the one or
the other, cand cannot freely intermingle these cases.

======================================================================
References:
-----------
"To verbize one's nouns" -- the concept of "Lexical Implication Rules": 
N. Ostler, B.T.S.Atkins, "Predictable Meaning Shift: Some Linguistic
Properties of Lexical Implication Rules", (1991) Proceedings of the
First SIGLEX Workshop on Lexical Semantics and Knowledge Representation
